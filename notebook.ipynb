{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regensburg Pediatric Appendicitis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mutual_info_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# fetch dataset \n",
    "regensburg_pediatric_appendicitis = fetch_ucirepo(id=938)   \n",
    "# data (as pandas dataframes) \n",
    "X = regensburg_pediatric_appendicitis.data.features \n",
    "y = regensburg_pediatric_appendicitis.data.targets \n",
    "df = pd.concat([X, y], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning + Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe from the info that some columns have majority of values null and it would be best to drop them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cols = df.columns\n",
    "row, column = df.shape\n",
    "keep_cols = []\n",
    "for col in df_cols:\n",
    "    if ((df[col].isna().sum()/column)*100) > 50:\n",
    "        continue\n",
    "    keep_cols.append(col)\n",
    "df_new = df.loc[:, keep_cols]\n",
    "df_new.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data looks much better now after dropping columns that are not needed. We will prepare the data before training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the remaining columns with few missing values, we will eaither fill them with mean or mode based on the data type (numerical or categorical). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = df_new.select_dtypes(include='number').columns\n",
    "cat_cols = df_new.select_dtypes(exclude='number').columns\n",
    "df_new = df_new.loc[~(df_new.Management.isna() | df_new.Severity.isna() | df_new.Diagnosis.isna())]\n",
    "df_new.dropna(thresh=5, inplace=True)\n",
    "\n",
    "for col in num_cols:\n",
    "    df_new.loc[df_new[col].isna(), col] = df_new[col].mean()\n",
    "    if col in ['Length_of_Stay', 'Thrombocyte_Count', 'CRP', 'US_Number', 'Age']:\n",
    "        df_new[col] = df_new[col].astype(int)\n",
    "\n",
    "for col in cat_cols:\n",
    "    df_new[col] = df_new[col].astype('category')\n",
    "    df_new.loc[df_new[col].isna(), col] = df_new[col].mode()[0]\n",
    "\n",
    "df_new.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "num_matrix = df_new.select_dtypes(include='number').corr()\n",
    "sns.heatmap(num_matrix, annot=True, mask=np.triu(num_matrix))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the column Weight is highly correlated with various columns so it would be best to drop those columns as weight is an import feature when considering pediatrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "key_pair = set()\n",
    "df_temp = df_new.dropna()\n",
    "for col_x in cat_cols[:-3]:\n",
    "    for col_y in y.columns:\n",
    "        if col_x != col_y:\n",
    "            if (col_y, col_x) not in key_pair:\n",
    "                mis = mutual_info_score(df_temp[col_x], df_temp[col_y])\n",
    "                # print(f'MIS of {col_x=} and {col_y=} is {round(mis,4)}')\n",
    "                scores.append(((col_x, col_y), round(mis,4)))\n",
    "scores.sort(key=lambda x: x[1], reverse=True)\n",
    "for x, mis in scores:\n",
    "    col_x, col_y = x\n",
    "    print(f'MIS of {col_x=} and {col_y=} is {mis=}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering the original problem had Management, Severity and Diagnosis as their target variables, we see we can get more information about Diagnosis and Severity from feature variables most of the time.  \n",
    "\n",
    "We see columns such as Appendix_on_US, Loss_of_Appetite, and Nausea have considerable MIS which can be used to predict Diagnosis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.loc[df_new.Age == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above samples indicate information about patients that are babies. Babies with height and weight below average of their age group show complicated case of appendicitis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.describe(exclude='number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.Stool.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.loc[df_new.Stool == 'constipation, diarrhea']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will remove this row to avoid confusion. It should be learnt that this patient had a compicated case of appenditis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df_new.loc[df_new.Stool != 'constipation, diarrhea', :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.Management.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.loc[df_new.Management == 'simultaneous appendectomy', :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would be best to remove the row as this is an outlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df_new.loc[df.Management != 'simultaneous appendectomy', :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(8, 4), nrows=1, ncols=2, sharey=True)\n",
    "sns.histplot(data=df, x='Age', hue='Diagnosis', kde=True, ax=axes[0], multiple='stack')\n",
    "sns.histplot(data=df.loc[df.Diagnosis=='appendicitis', :], x='Age', hue='Severity', kde=True, ax=axes[1], multiple='stack')\n",
    "axes[0].set_title('Age Distribution of all patients', fontsize=10)\n",
    "axes[1].set_title('Age Distribution of appendicitis patients', fontsize=10)\n",
    "fig.suptitle('Age Distribution', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that 10-12 year olds constitute the largest age group of people in the dataset and while most of them are diagnosed with appendicitis, majority of cases are not complicated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(10, 8), nrows=2, ncols=2)\n",
    "diagnosis = ['appendicitis', 'no appendicitis']\n",
    "severity = ['uncomplicated', 'complicated']\n",
    "\n",
    "sns.boxplot(x='Length_of_Stay', y='Diagnosis', data=df_new, ax=axes[0][0])\n",
    "axes[0][0].set_yticklabels(diagnosis, rotation=90, fontsize=8)\n",
    "sns.boxplot(x='Length_of_Stay', y='Severity', data=df_new, ax=axes[0][1])\n",
    "axes[0][1].set_yticklabels(severity, rotation=90, fontsize=8)\n",
    "sns.boxplot(x='Weight', y='Diagnosis', data=df_new, ax=axes[1][0])\n",
    "axes[1][0].set_yticklabels(diagnosis, rotation=90, fontsize=8)\n",
    "sns.boxplot(x='Weight', y='Severity', data=df_new, ax=axes[1][1])\n",
    "axes[1][1].set_yticklabels(severity, rotation=90, fontsize=8)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(10, 8), nrows=2, ncols=2)\n",
    "diagnosis = ['appendicitis', 'no appendicitis']\n",
    "severity = ['uncomplicated', 'complicated']\n",
    "\n",
    "sns.boxplot(x='Thrombocyte_Count', y='Diagnosis', data=df_new, ax=axes[0][0])\n",
    "axes[0][0].set_yticklabels(diagnosis, rotation=90, fontsize=8)\n",
    "sns.boxplot(x='Thrombocyte_Count', y='Severity', data=df_new, ax=axes[0][1])\n",
    "axes[0][1].set_yticklabels(severity, rotation=90, fontsize=8)\n",
    "sns.boxplot(x='Body_Temperature', y='Diagnosis', data=df_new, ax=axes[1][0])\n",
    "axes[1][0].set_yticklabels(diagnosis, rotation=90, fontsize=8)\n",
    "sns.boxplot(x='Body_Temperature', y='Severity', data=df_new, ax=axes[1][1])\n",
    "axes[1][1].set_yticklabels(severity, rotation=90, fontsize=8)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering some of the numerical columns that showed high standard variations and significantly high maximum, we observe that the columns have outliers and are right-skewed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will train various models to see which one will be appropriate to predict Diagnosis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = df_new[['Weight', 'Sex', 'Length_of_Stay', 'Appendix_on_US', 'Migratory_Pain', 'Lower_Right_Abd_Pain',\n",
    "       'Contralateral_Rebound_Tenderness', 'Coughing_Pain', 'Nausea', 'Loss_of_Appetite', 'Body_Temperature',\n",
    "       'WBC_Count', 'RBC_Count', 'Hemoglobin', 'RDW', 'Thrombocyte_Count', 'CRP', 'Stool', 'Peritonitis', 'US_Number']]\n",
    "\n",
    "target = df_new['Diagnosis']\n",
    "labelencoder = LabelEncoder()\n",
    "labelencoder.fit(target)\n",
    "target = labelencoder.transform(target)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_model, target, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regression  \n",
    "\n",
    "We will start Random Forest Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv = DictVectorizer(sparse=False)\n",
    "X_train_dv = dv.fit_transform(X_train.to_dict(orient='records'))\n",
    "X_test_dv = dv.transform(X_test.to_dict(orient='records'))\n",
    "\n",
    "params = {'n_estimators': [75, 100, 125, 150],'max_depth': [5, 10, 15, 20], 'max_features': ['auto','sqrt', 'log2']}\n",
    "\n",
    "rfc_model = RandomForestClassifier(random_state=42)\n",
    "grid_search = GridSearchCV(estimator=rfc_model, param_grid=params, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train_dv, y_train)\n",
    "rfc_best_model = grid_search.best_estimator_\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rfc_best_model.predict(X_test_dv)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_importance = pd.DataFrame({'features': dv.feature_names_, 'importance':rfc_best_model.feature_importances_})\n",
    "rfc_importance.sort_values(by='importance', ascending=False).head(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy wise Random Forest does a great job. We see that body characteristics such as WBC_Count, Weight, Body_Temperature as well as type of surgery such as Appendix needed on US or how long a patient had to stay in hospital are the most important factors for predicting the outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv = DictVectorizer(sparse=False)\n",
    "X_train_dv = dv.fit_transform(X_train.to_dict(orient='records'))\n",
    "X_test_dv = dv.transform(X_test.to_dict(orient='records'))\n",
    "\n",
    "params = {'penalty': [None, 'l1', 'l2', 'elasticnet'], 'C': [0.01, 0.1, 0.5, 1], 'l1_ratio': [0.1, 0.5, 0.9]}\n",
    "log_model = LogisticRegression(random_state=42, multi_class='ovr')\n",
    "\n",
    "grid_search = GridSearchCV(estimator=log_model, param_grid=params, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train_dv, y_train)\n",
    "log_best_model = grid_search.best_estimator_\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (log_best_model.predict_proba(X_test_dv)[:, 1]) >= 0.5\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_weights = pd.DataFrame({'features': dv.feature_names_, 'weights':log_best_model.coef_[0]})\n",
    "log_weights.sort_values(by='weights', ascending=False).head(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression does a less impressive job and we see it gave different degree of importance to certain variables than Random Forest did."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_torch = torch.tensor(X_train_dv).float()\n",
    "X_test_torch = torch.tensor(X_test_dv) .float()\n",
    "y_train_torch = torch.tensor(y_train).flatten().float()\n",
    "y_test_torch = torch.tensor(y_test).flatten().float()\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Define the model\n",
    "class SimpleClassifier(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(SimpleClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(64, 16)\n",
    "        self.fc3 = nn.Linear(16, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "# Define model hyperparameters\n",
    "input_size = X_train_dv.shape[1]  # Adjust based on the number of features in your dataset\n",
    "output_size = 1   # Binary classification has one output node with sigmoid activation\n",
    "\n",
    "# Instantiate the model\n",
    "\n",
    "model = SimpleClassifier(input_size,  output_size)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 5000\n",
    "for epoch in range(num_epochs):\n",
    "    outputs = model(X_train_torch).flatten()\n",
    "    loss = criterion(outputs, y_train_torch)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch+1) % 250 == 0: \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad(): \n",
    "    y_pred = model(X_test_torch)\n",
    "    _, predicted = torch.max(y_pred, dim=1) \n",
    "    accuracy = (predicted == y_test_torch).float().mean() \n",
    "    print(f'Test Accuracy: {accuracy.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "X_train_dv = dv.fit_transform(X_train.to_dict(orient='records'))\n",
    "X_test_dv = dv.transform(X_test.to_dict(orient='records'))\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train_dv.shape[1], activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming X_train and y_train are your training data and labels\n",
    "model.fit(X_train_dv, y_train, epochs=50, batch_size=32, validation_split=0.4, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test_dv, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow did a fine job overall.\n",
    "\n",
    "Overall, Random Forest Classifier did an excellent job in predicting the diagnosis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing\n",
    "\n",
    "The cell block should be run only when running `predict.py`` or the model is deployed via docker or online."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def clean_data(df):\n",
    "    '''\n",
    "    Cleans the data before used for training our model\n",
    "    '''\n",
    "    df_cols = df.columns\n",
    "    _, column = df.shape\n",
    "    # remove null values\n",
    "    keep_cols = []\n",
    "    for col in df_cols:\n",
    "        if ((df[col].isna().sum()/column)*100) > 50:\n",
    "            continue\n",
    "        keep_cols.append(col)\n",
    "    \n",
    "    df_new = df.loc[:, keep_cols]\n",
    "    \n",
    "    # impute misisng values\n",
    "    num_cols = df_new.select_dtypes(include='number').columns\n",
    "    cat_cols = df_new.select_dtypes(exclude='number').columns\n",
    "    # print(df_new.columns,'\\n')\n",
    "    df_new = df_new.loc[~(df_new.Management.isna() | df_new.Severity.isna() | df_new.Diagnosis.isna())]\n",
    "    df_new.dropna(thresh=5, inplace=True)\n",
    "\n",
    "    for col in num_cols:\n",
    "        df_new.loc[df_new[col].isna(), col] = df_new[col].mean()\n",
    "        if col in ['Length_of_Stay', 'Thrombocyte_Count', 'CRP', 'US_Number', 'Age']:\n",
    "            df_new[col] = df_new[col].astype(int)\n",
    "\n",
    "    for col in cat_cols:\n",
    "        df_new[col] = df_new[col].astype('category')\n",
    "        df_new.loc[df_new[col].isna(), col] = df_new[col].mode()[0]\n",
    "        \n",
    "    # Remove outlier values\n",
    "    df_new = df_new.loc[df_new.Stool != 'constipation, diarrhea', :]\n",
    "    df_new = df_new.loc[df.Management != 'simultaneous appendectomy', :]\n",
    "    target = df_new.loc[:, 'Diagnosis']\n",
    "    df_new = df_new[['Weight', 'Sex', 'Length_of_Stay', 'Appendix_on_US', 'Migratory_Pain', 'Lower_Right_Abd_Pain',\n",
    "       'Contralateral_Rebound_Tenderness', 'Coughing_Pain', 'Nausea', 'Loss_of_Appetite', 'Body_Temperature',\n",
    "       'WBC_Count', 'RBC_Count', 'Hemoglobin', 'RDW', 'Thrombocyte_Count', 'CRP', 'Stool', 'Peritonitis', 'US_Number']]\n",
    "    # df_new = df_new[['Length_of_Stay', 'RBC_Count', 'WBC_Count', 'Weight', 'Thrombocyte_Count', 'Body_Temperature',\n",
    "    #                  'Appendix_on_US', 'CRP', 'Peritonitis', 'Hemoglobin']]\n",
    "    return df_new, target\n",
    "\n",
    "regensburg_pediatric_appendicitis = fetch_ucirepo(id=938)\n",
    "X = regensburg_pediatric_appendicitis.data.features \n",
    "y = regensburg_pediatric_appendicitis.data.targets \n",
    "df = pd.concat([X, y], axis=1)\n",
    "\n",
    "X, target = clean_data(df)\n",
    "\n",
    "_, X_test, _, y_test = train_test_split(X, target, train_size=0.6, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Weight': 48.0, 'Sex': 'male', 'Length_of_Stay': 3, 'Appendix_on_US': 'no', 'Migratory_Pain': 'no', 'Lower_Right_Abd_Pain': 'yes', 'Contralateral_Rebound_Tenderness': 'yes', 'Coughing_Pain': 'yes', 'Nausea': 'no', 'Loss_of_Appetite': 'no', 'Body_Temperature': 38.8, 'WBC_Count': 11.4, 'RBC_Count': 5.23, 'Hemoglobin': 13.8, 'RDW': 13.5, 'Thrombocyte_Count': 276, 'CRP': 1, 'Stool': 'normal', 'Peritonitis': 'no', 'US_Number': 413} \n",
      "\n",
      " {'probability': 1.0, 'result': 'Person does not have appenditic'} \n",
      "\n",
      "Actual result is  no appendicitis\n"
     ]
    }
   ],
   "source": [
    "import requests \n",
    "import random \n",
    "import pickle\n",
    "\n",
    "with open('le.bin', 'rb') as f:\n",
    "    labelencoder = pickle.load(f)\n",
    "\n",
    "url = \"http://10.0.0.7:9696/predict\"\n",
    "\n",
    "choice = random.randint(0, 311)\n",
    "sample = X_test.iloc[choice, :].to_dict()\n",
    "response = requests.post(url, json=sample).json()\n",
    "\n",
    "print(sample, '\\n\\n', response, '\\n\\n' \"Actual result is \", y_test.iloc[choice])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
